# Organizational Evidence: Quality Assessment
# Evaluate the credibility and usefulness of organizational data collected

## Logic Model Context
**Research Question:** Does employee compensation impact turnover in trucking through productivity and organizational commitment mediators?

**Logic Model:** Compensation [X] → Productivity [Mediator 1] → Organizational Commitment [Mediator 2] → Staff Turnover [Y]

**Data Sources:** Bureau of Labor Statistics (BLS) databases - JOLTS, OEWS, CES, Labor Productivity Program, Employee Tenure Survey, IIF, Union Members Survey

---

## Data Quality Barrier Assessment

### Barrier 1: Absence of a Logic Model

#### **Applicability to This Project:**
**NOT APPLICABLE** - This barrier does not affect our organizational evidence.

#### **Assessment:**
- ✅ **We have a clear logic model:** Compensation [X] → Productivity [Mediator 1] → Organizational Commitment [Mediator 2] → Staff Turnover [Y]
- ✅ **Logic model guides variable selection:** Each BLS dataset was selected to measure specific components of the causal chain
- ✅ **Logic model enables hypothesis testing:** We can test relationships between variables rather than just describing patterns

#### **Seriousness if Present:**
**CRITICAL** - Without a logic model, researchers engage in "data fishing" - looking for any interesting patterns without theoretical justification. This leads to:
- Spurious correlations (finding relationships that don't exist)
- Inability to distinguish cause from effect
- No framework for deciding what data to collect
- Results that cannot inform action

#### **Can It Be Addressed?**
**YES - Easily addressable** 
- Develop logic model before data collection using:
  - Literature review (what theory/research suggests causes outcomes)
  - Stakeholder input (practitioner theories of change)
  - Existing frameworks (PICOC, theory of planned behavior, etc.)
- Logic model should specify: independent variable(s), mediators/moderators, dependent variable, and expected relationships

#### **Our Mitigation:**
- Logic model developed in Ask phase based on scientific literature
- All organizational data collection explicitly mapped to logic model components
- Analysis plan tests specific hypothesized relationships, not exploratory fishing

---

### Barrier 2: Irrelevant Data

#### **Applicability to This Project:**
**PARTIALLY APPLICABLE** - Some data limitations exist.

#### **Assessment:**
**Relevant Data:**
- ✅ Turnover rates (JOLTS) - directly measures [Y] dependent variable
- ✅ Wages/compensation (OEWS, CES) - directly measures [X] independent variable
- ✅ Productivity (Labor Productivity Program) - directly measures Mediator 1

**Irrelevant/Missing Data:**
- ⚠️ **Organizational commitment not directly measured** - BLS doesn't survey employee commitment, loyalty, or engagement
- ⚠️ **Aggregated industry data** - Cannot isolate specific company practices (e.g., which companies offer flexible scheduling, procedural justice)
- ⚠️ **Limited contextual variables** - Missing data on management quality, workplace culture, career development opportunities

#### **Seriousness:**
**MODERATE** - Core logic model variables are measured (X, Y, partial mediators), but missing direct measure of organizational commitment requires using proxy variables (tenure, injury rates, unionization) which are imperfect.

#### **Can It Be Addressed?**
**YES - Partially addressable through:**
1. **Using proxy measures** - Tenure, injury rates, and unionization serve as indirect commitment indicators
2. **Triangulation with other evidence types** - Supplement with:
   - Scientific evidence on commitment mechanisms
   - Practitioner evidence on what builds commitment
   - Stakeholder evidence (surveys) measuring commitment directly
3. **Primary data collection** - Could conduct targeted surveys of trucking employees measuring organizational commitment directly

#### **Our Mitigation:**
- Using multiple proxy measures for commitment (tenure, safety, unionization)
- Acknowledging limitations in synthesis
- Combining with scientific literature that measures commitment directly
- Recommending primary data collection for future research

---

### Barrier 3: Inaccurate Data

#### **Applicability to This Project:**
**LOW APPLICABILITY** - BLS data has high accuracy.

#### **Assessment:**
**Data Accuracy Strengths:**
- ✅ **Rigorous methodology** - BLS uses probability sampling, survey pretesting, validation checks
- ✅ **Large sample sizes** - JOLTS (21,000 establishments), OEWS (1.1M establishments), CES (131,000 businesses)
- ✅ **Multiple quality checks** - Data editing, outlier detection, consistency checks
- ✅ **Government verification** - Independent verification, no commercial bias
- ✅ **Transparent methodology** - Full documentation of data collection procedures

**Potential Accuracy Issues:**
- ⚠️ **Non-response bias** - Not all establishments participate; non-respondents may differ systematically
- ⚠️ **Reporting errors** - Establishments may misreport (intentionally or unintentionally)
- ⚠️ **Classification errors** - Workers/establishments may be miscategorized by industry/occupation

#### **Seriousness:**
**LOW** - BLS is considered "gold standard" for labor market data. While perfect accuracy is impossible, error rates are minimal and well-documented.

#### **Can It Be Addressed?**
**ALREADY ADDRESSED** - BLS implements best practices:
- Statistical weighting to adjust for non-response
- Multiple imputation for missing data
- Standard error calculations to quantify uncertainty
- Historical consistency checks

#### **Our Mitigation:**
- Using BLS standard errors/confidence intervals in analysis
- Acknowledging measurement error exists but is minimal
- Reporting uncertainty ranges rather than point estimates
- Comparing across multiple BLS surveys for validation (e.g., CES earnings vs. OEWS wages)

---

### Barrier 4: Missing Contextual Information

#### **Applicability to This Project:**
**HIGHLY APPLICABLE** - This is a significant limitation.

#### **Assessment:**
**What's Missing:**
- ❌ **"Why" explanations** - Numbers show turnover is high, but not *why* drivers quit
- ❌ **Voluntary vs. involuntary distinctions** - JOLTS separates quits from layoffs, but not reasons within each category
- ❌ **Company-specific practices** - Cannot identify which companies have better retention or what they do differently
- ❌ **Temporal context** - Don't know if recent events (economic shocks, regulation changes, pandemic effects) distort patterns
- ❌ **Regional variations** - Industry-level aggregates mask geographic differences (rural vs. urban, regional wage differences)
- ❌ **Worker characteristics** - Limited demographics; can't distinguish long-haul vs. local drivers, owner-operators vs. company drivers

#### **Seriousness:**
**HIGH** - Context is essential for:
- Understanding *mechanisms* (how X causes Y)
- Identifying *actionable interventions* (what managers can actually do)
- Avoiding *misinterpretation* (attributing turnover to wrong causes)
- Assessing *generalizability* (whether patterns apply to specific companies)

#### **Can It Be Addressed?**
**YES - Through evidence triangulation:**
1. **Scientific evidence** - Experimental studies explain causal mechanisms
2. **Practitioner evidence** - Case studies provide company-specific context
3. **Stakeholder evidence** - Interviews/surveys capture "why" from drivers and managers
4. **Industry reports** - Trade associations provide qualitative context
5. **Supplementary BLS products** - Industry profiles, regional reports add context

#### **Our Mitigation:**
- **Explicitly acknowledging** that organizational data shows "what" not "why"
- **Combining with qualitative evidence** from practitioner and stakeholder sources
- **Using scientific literature** to explain mechanisms behind statistical patterns
- **Reporting limitations** - Being clear that aggregated data cannot answer all questions
- **Recommending mixed methods** - Suggesting case studies and interviews to add context

---

### Barrier 5: Measurement Error(s)

#### **Applicability to This Project:**
**MODERATELY APPLICABLE** - Errors exist but are quantified.

#### **Assessment:**
**Sources of Measurement Error:**

**Sampling Error:**
- ⚠️ JOLTS samples 21,000 establishments; trucking subset is smaller
- ⚠️ Smaller samples = wider confidence intervals
- ⚠️ Monthly volatility due to sampling variation

**Non-response Error:**
- ⚠️ Not all sampled establishments participate (response rates vary by survey)
- ⚠️ Non-respondents may differ from respondents (non-response bias)

**Reporting Error:**
- ⚠️ Establishments may miscount separations, hours, wages
- ⚠️ Timing issues (reporting period vs. reference period mismatches)

**Coverage Error:**
- ⚠️ Some establishments excluded from sampling frame (small businesses, informal sector)
- ⚠️ Gig economy workers, independent contractors not fully captured

**Processing Error:**
- ⚠️ Data entry errors, coding errors, imputation errors

#### **Seriousness:**
**MODERATE** - Errors are:
- **Quantified:** BLS reports standard errors, confidence intervals, relative standard errors (RSEs)
- **Generally small:** Large sample sizes minimize sampling error
- **Systematic:** BLS uses consistent methodology across time, enabling valid trend analysis even if levels have some error

#### **Can It Be Addressed?**
**PARTIALLY - BLS already implements mitigation strategies:**
- ✅ **Statistical weighting** to adjust for non-response and coverage
- ✅ **Imputation methods** for missing data
- ✅ **Quality control procedures** to minimize reporting/processing errors
- ✅ **Standard error calculations** to quantify uncertainty

**Additional Mitigation:**
- Report confidence intervals, not just point estimates
- Use multiple data sources for validation (triangulation)
- Focus on large, statistically significant patterns rather than small differences
- Use moving averages to smooth monthly volatility

#### **Our Mitigation:**
- **Acknowledging uncertainty** - Including standard errors in reported statistics
- **Conservative interpretation** - Not over-interpreting small differences within margin of error
- **Trend analysis** - Focusing on consistent patterns over time rather than month-to-month fluctuations
- **Multiple indicators** - Using convergent evidence from multiple BLS surveys

---

### Barrier 6: Small Number Problem

#### **Applicability to This Project:**
**LOW TO MODERATE APPLICABILITY** - Depends on level of analysis.

#### **Assessment:**
**When Small Numbers Are NOT a Problem:**
- ✅ **Industry-level analysis** - Truck transportation (NAICS 484) has 1.5M+ employees, providing large sample
- ✅ **Major occupation groups** - Heavy truck drivers (892,450 employed) have sufficient sample size
- ✅ **National estimates** - Aggregating across U.S. provides robust sample

**When Small Numbers COULD Be a Problem:**
- ⚠️ **Detailed occupations** - Specialized driver types (hazmat, oversized load) may have small samples
- ⚠️ **Geographic subgroups** - State or metro area estimates have smaller samples, wider confidence intervals
- ⚠️ **Cross-tabulations** - Analyzing intersections (e.g., female drivers in rural areas) quickly reduces sample size
- ⚠️ **Small companies** - Data suppressed when cell sizes too small for confidentiality

#### **Seriousness:**
**LOW** - For our analysis at industry/national level with major occupation groups:
- Adequate sample sizes for reliable estimates
- BLS suppresses unreliable estimates (protecting us from using bad data)
- Can aggregate up to broader categories if needed

**MODERATE** - If we wanted to analyze:
- Specific company types or sizes
- Granular geographic areas
- Detailed demographic subgroups
- Rare occupations or events

#### **Can It Be Addressed?**
**YES - Through design choices:**
1. **Use broader categories** - Analyze NAICS 484 overall rather than 4-digit sub-industries
2. **Aggregate across time** - Use annual averages rather than single months
3. **Aggregate geographically** - Use regions rather than states, national rather than regional
4. **Check data suppression flags** - BLS indicates when estimates are unreliable
5. **Report confidence intervals** - Wide intervals signal small sample issues

#### **Our Mitigation:**
- **Using industry-level data** (NAICS 484) with large samples
- **Focusing on major occupations** (heavy truck drivers, not rare specializations)
- **National-level analysis** rather than state/local breakdowns
- **Avoiding over-segmentation** - Not cross-tabulating multiple variables that fragment sample
- **Checking RSEs (Relative Standard Errors)** - BLS guidance: RSE >30% = unreliable, 20-30% = use with caution

---

### Barrier 7: Confusing Percentages/Averages

#### **Applicability to This Project:**
**MODERATELY APPLICABLE** - Requires careful interpretation.

#### **Assessment:**
**Potential Confusion Points:**

**Rates vs. Counts:**
- ⚠️ JOLTS reports *rates* (3.2% monthly separations) not *counts*
- ⚠️ Must annualize monthly rates carefully (not simply 3.2% × 12 = 38.4% due to compounding)
- ⚠️ Rates are per 100 employees; must adjust for workforce size to get totals

**Means vs. Medians:**
- ⚠️ OEWS reports *mean* wages ($29.02/hr) which are pulled up by high earners
- ⚠️ *Median* wages ($28.19/hr) better represent "typical" driver
- ⚠️ Must specify which measure used in analysis

**Weighted vs. Unweighted Averages:**
- ⚠️ Industry averages weighted by employment size
- ⚠️ Small companies with different wage structures may be underweighted

**Percentiles:**
- ⚠️ Wage distribution percentiles (10th, 25th, 75th, 90th) can be misinterpreted
- ⚠️ "25th percentile = $23.54/hr" means 25% earn *less* than this, not that this is average for bottom quarter

**Trend vs. Level:**
- ⚠️ Productivity *index* (104.2, base year 2017=100) shows relative change, not absolute level

#### **Seriousness:**
**MODERATE** - Misinterpreting statistics leads to:
- Incorrect problem magnitude estimates
- Faulty intervention sizing (e.g., wrong wage increase amount)
- Misleading comparisons across data sources
- Erroneous conclusions about trends

#### **Can It Be Addressed?**
**YES - Through careful documentation:**
1. **Define all metrics clearly** - Specify whether using rates/counts, means/medians, monthly/annual
2. **Show calculations** - Demonstrate how annualized rates were computed
3. **Use multiple measures** - Report both mean and median; both rates and counts
4. **Provide reference populations** - Clarify denominators for percentages
5. **Include distribution information** - Report percentiles, not just central tendency

#### **Our Mitigation:**
- **Clear metric definitions** - Specifying "3.2% monthly separations rate = ~38.4% annualized"
- **Reporting both mean and median** wages to show distribution
- **Explaining indices** - Noting productivity index is relative to 2017 baseline
- **Consistent terminology** - Using same metric labels throughout analysis
- **Benchmark comparisons** - Showing trucking rates vs. all-industry rates for context

---

### Barrier 8: Misleading Graphs

#### **Applicability to This Project:**
**LOW CURRENT APPLICABILITY** - We're working with data tables, not graphs yet.

#### **Assessment:**
**Potential Graph Pitfalls if We Create Visualizations:**

**Scale Manipulation:**
- ⚠️ Truncated y-axis makes small differences look large
- ⚠️ Example: Showing turnover from 35-40% instead of 0-40% exaggerates variation

**Inappropriate Chart Types:**
- ⚠️ Pie charts for more than 3-4 categories become unreadable
- ⚠️ Dual-axis charts can create false correlations by choosing arbitrary scales

**Cherry-picked Time Periods:**
- ⚠️ Showing only recent uptick in wages without longer-term context
- ⚠️ Starting trend lines at convenient points to suggest desired pattern

**Missing Uncertainty:**
- ⚠️ Plotting point estimates without confidence intervals overstates precision
- ⚠️ Line graphs connecting monthly points suggest more precision than exists with sampling error

**Inappropriate Comparisons:**
- ⚠️ Comparing absolute values across different-sized populations
- ⚠️ Not adjusting for inflation when showing wages over time

#### **Seriousness:**
**LOW NOW, but POTENTIALLY HIGH if graphs are created improperly**
- Misleading visualizations are more persuasive than misleading tables
- Decision-makers often rely on graphs more than reading full data
- Bad graphs can lead to completely wrong conclusions despite correct underlying data

#### **Can It Be Addressed?**
**YES - Through visualization best practices:**
1. **Use appropriate scales** - Start y-axis at zero for bar charts; use full range for line charts
2. **Show uncertainty** - Include confidence interval bands or error bars
3. **Label clearly** - Specify units, time periods, populations
4. **Choose right chart type** - Bar charts for comparisons, line charts for trends, scatter plots for relationships
5. **Avoid 3D effects** - Stick to 2D for accurate perception
6. **Use consistent scales** - Same scale across related charts for valid comparisons
7. **Annotate context** - Note major events, policy changes that might explain patterns

#### **Our Mitigation:**
- **If creating graphs, following best practices** outlined above
- **Having peer review visualizations** before finalizing
- **Providing data tables alongside graphs** for transparency
- **Using professional tools** (Excel, Tableau, R ggplot2) with good defaults
- **Currently using tables** which are less prone to visual manipulation

---

### Barrier 9: Correlations/Regressions/Overfitting

#### **Applicability to This Project:**
**HIGHLY APPLICABLE** - This is the most serious barrier for causal inference.

#### **Assessment:**
**The Fundamental Problem:**
- ❌ **Observational data cannot prove causation** - BLS data is not experimental
- ❌ **Correlation ≠ Causation** - Even strong statistical relationships don't prove compensation *causes* reduced turnover
- ❌ **Confounding variables** - Many unmeasured factors affect both compensation and turnover:
  - Management quality (good managers may both pay more AND retain better)
  - Company culture (positive culture may drive both higher wages and lower turnover)
  - Regional labor markets (tight markets may force higher wages while turnover remains high)
  - Technology/equipment (better trucks may attract drivers, companies with better equipment may also pay more)
  - Working conditions (safety, schedule, home time)

**Specific Threats:**

**Reverse Causality:**
- ⚠️ Does higher pay → lower turnover? OR
- ⚠️ Does lower turnover → higher pay? (Companies with stable workforces can afford to pay more due to lower recruitment costs)

**Selection Bias:**
- ⚠️ High-wage companies may attract different workers (more experienced, more stable, different preferences)
- ⚠️ Cannot determine if wages reduce turnover or if stable workers select into high-wage jobs

**Omitted Variable Bias:**
- ⚠️ If management quality affects both wages and turnover, but we don't measure it, we'll attribute turnover effects to wages that are really from management

**Overfitting Risk:**
- ⚠️ Running multiple regressions on same dataset increases false positive risk
- ⚠️ Finding "significant" relationships by chance (p-hacking)

#### **Seriousness:**
**CRITICAL** - This is THE major threat to validity for organizational data:
- Cannot make confident causal claims from BLS data alone
- Policy recommendations based on spurious correlations could backfire
- Example: If we conclude "raise wages by $5/hr to cut turnover 20%" but real cause is management quality, wage increases will fail

#### **Can It Be Addressed?**
**PARTIALLY - Cannot fully solve with observational data, but can mitigate:**

**Within Organizational Data:**
1. **Panel data methods** - Use time-series with fixed effects to control for unobserved company characteristics
2. **Natural experiments** - Look for policy changes (minimum wage increases, regulation changes) that create quasi-experimental variation
3. **Instrumental variables** - Find variables that affect wages but not turnover directly (difficult to identify valid instruments)
4. **Propensity score matching** - Compare similar companies with different wage levels

**Through Evidence Triangulation (CRITICAL):**
5. **Scientific evidence** - Use RCTs, quasi-experiments from literature to establish causation
6. **Practitioner evidence** - Case studies showing before/after changes when companies raised wages
7. **Theory/mechanisms** - Use scientific literature to explain *how* compensation affects commitment/turnover
8. **Stakeholder evidence** - Ask drivers "Would higher pay make you stay?" to assess plausibility

**Statistical Safeguards:**
9. **Bonferroni correction** - Adjust significance thresholds for multiple comparisons
10. **Cross-validation** - Test models on held-out data
11. **Report effect sizes** - Not just p-values
12. **Transparent analysis** - Pre-register hypotheses; report all tests run

#### **Our Mitigation:**
- **Clearly labeling organizational data as DESCRIPTIVE** - Shows patterns, not causation
- **Using logic model from scientific literature** - Causal mechanisms established by experiments, not our observational data
- **Triangulating with experimental evidence** - Scientific evidence provides causal claims; organizational data shows if patterns exist in real-world context
- **Acknowledging confounds** - Explicitly discussing alternative explanations
- **Conservative language** - "Associated with" not "causes"; "suggests" not "proves"
- **Recommending pilot testing** - Any interventions should be tested on small scale before full implementation

**Critical Recognition:**
- BLS data answers: "Are high-wage trucking companies different in turnover?" (descriptive)
- Scientific literature answers: "Does raising wages *cause* lower turnover?" (causal)
- Both types of evidence are needed for evidence-based practice

---

### Barrier 10: Wide Confidence Intervals

#### **Applicability to This Project:**
**MODERATELY APPLICABLE** - Uncertainty exists but is manageable.

#### **Assessment:**
**Sources of Uncertainty:**

**Sampling Variation:**
- ⚠️ JOLTS trucking estimates based on subset of 21,000 total establishments
- ⚠️ Monthly turnover rate (3.2%) has standard error → confidence interval
- ⚠️ Smaller subgroups (state-level, detailed occupations) have wider intervals

**Relative Standard Errors (RSEs):**
- BLS reports RSEs for each estimate
- RSE = (Standard Error / Estimate) × 100
- BLS guidelines:
  - RSE < 20%: Estimate is reliable
  - RSE 20-30%: Use with caution
  - RSE > 30%: Estimate not reliable enough to publish

**Example Industry-Level RSEs (typical):**
- ✅ National JOLTS separations rate: RSE ~2-3% (very reliable)
- ✅ National OEWS mean wage: RSE ~1-2% (very reliable)
- ⚠️ State-level estimates: RSE ~10-15% (reliable but less precise)
- ❌ Small occupation/state cross-tabs: RSE >30% (often suppressed)

**Monthly Volatility:**
- Even with reliable estimates, month-to-month fluctuations may reflect sampling variation not real changes
- Example: Turnover rate varying 3.0-3.4% monthly could be noise, not trend

#### **Seriousness:**
**MODERATE** - Wide confidence intervals mean:
- Cannot detect small effect sizes (might miss small but important changes)
- Difficult to distinguish real trends from random variation
- Uncertainty about precise magnitudes (know turnover is "high" but exact rate uncertain)
- Limits ability to forecast or set precise targets

**However, for our analysis:**
- Industry-level estimates have narrow confidence intervals (high reliability)
- Large effects (38% turnover vs. national 32%) are well outside margin of error
- Broad patterns are clear even with some uncertainty

#### **Can It Be Addressed?**
**YES - Through:**
1. **Using higher-level aggregates** - National > Regional > State > Local
2. **Pooling across time** - Annual averages smoother than monthly estimates
3. **Larger sample surveys** - OEWS (1.1M establishments) has narrower CIs than JOLTS (21K)
4. **Reporting intervals, not point estimates** - "Turnover rate is 3.0-3.4%" vs. "exactly 3.2%"
5. **Focusing on significant differences** - Only interpret differences larger than 2× standard error
6. **Using moving averages** - 12-month rolling averages reduce volatility

#### **Our Mitigation:**
- **Reporting confidence intervals** where available
- **Using annual data** when available instead of single months
- **Comparing only large, meaningful differences** - Not interpreting small month-to-month changes
- **Checking RSEs** - Verifying estimates meet reliability thresholds
- **Conservative interpretation** - Acknowledging uncertainty in conclusions
- **Trend analysis over multiple time periods** - Looking for consistent patterns, not single data points

---

## Overall Data Quality Assessment

### Summary Table

| Barrier | Applicability | Seriousness | Addressable? | Our Mitigation Status |
|---------|--------------|-------------|--------------|---------------------|
| 1. Absence of Logic Model | ✅ Not Applicable | Critical if present | Easily | ✅ Strong - Logic model in place |
| 2. Irrelevant Data | ⚠️ Partial | Moderate | Partially | ✅ Good - Using proxies + triangulation |
| 3. Inaccurate Data | ✅ Low | Low | Already addressed | ✅ Strong - BLS high quality |
| 4. Missing Context | ⚠️ High | High | Yes, via triangulation | ⚠️ Moderate - Need to add qualitative evidence |
| 5. Measurement Error | ⚠️ Moderate | Moderate | Partially | ✅ Good - Using CIs, multiple sources |
| 6. Small Numbers | ✅ Low | Low | Yes, via aggregation | ✅ Strong - Using industry-level data |
| 7. Confusing Stats | ⚠️ Moderate | Moderate | Yes, via clear docs | ✅ Good - Defining all metrics clearly |
| 8. Misleading Graphs | ✅ Low (no graphs yet) | Potentially high | Yes, via best practices | ✅ Strong - Using tables; will follow best practices |
| 9. Correlation/Causation | ❌ High | **CRITICAL** | Partially | ⚠️ **Requires triangulation with experimental evidence** |
| 10. Wide CIs | ⚠️ Moderate | Moderate | Partially | ✅ Good - Reporting uncertainty |

---

### Confidence Level in Organizational Evidence

**HIGH CONFIDENCE for:**
- ✅ **Descriptive claims** - "Trucking turnover is 38% annually" (well-supported by reliable BLS data)
- ✅ **Comparative claims** - "Trucking wages increased 6% YoY" (accurate trend data)
- ✅ **Pattern identification** - "High turnover persists despite rising wages" (clear from multiple sources)

**MODERATE CONFIDENCE for:**
- ⚠️ **Magnitude estimates** - "Median tenure is 3.4 years" (reliable but has margin of error)
- ⚠️ **Proxy measures** - "Low tenure indicates low commitment" (reasonable but indirect)
- ⚠️ **Trend projections** - "If current trends continue..." (assumes stability)

**LOW CONFIDENCE for:**
- ❌ **Causal claims** - "Raising wages will reduce turnover" (**CANNOT conclude from organizational data alone**)
- ❌ **Mechanism explanations** - "Wages affect commitment which affects turnover" (requires experimental evidence)
- ❌ **Precise effect sizes** - "Each $1/hr wage increase reduces turnover by X%" (confounded)

---

### Critical Limitations to Acknowledge

1. **Organizational data is DESCRIPTIVE, not CAUSAL** - Shows associations, not cause-and-effect
2. **Aggregated industry data cannot identify specific interventions** - Need company-level case studies
3. **Missing direct measure of organizational commitment** - Using proxies with imperfect validity
4. **Limited contextual information** - Numbers don't explain "why" behind patterns
5. **Observational data has confounds** - Cannot isolate effects of compensation from other factors

---

### Recommendations for Strengthening Evidence Base

**Priority 1: Address Causation Barrier (Critical)**
- ✅ **Supplement with scientific evidence** - Use RCTs/quasi-experiments from literature to establish causal mechanisms
- ✅ **Conduct pilot tests** - If implementing interventions, use randomized rollout to test causality
- ✅ **Case studies** - Document before/after changes in companies that altered compensation

**Priority 2: Add Context (High Importance)**
- ✅ **Practitioner interviews** - Ask fleet managers what actually works for retention
- ✅ **Stakeholder surveys** - Ask drivers why they stay/leave, what would improve retention
- ✅ **Industry reports** - Review trade association qualitative research for context

**Priority 3: Improve Commitment Measurement (Moderate Importance)**
- ⚠️ **Primary data collection** - Survey drivers on organizational commitment using validated scales
- ⚠️ **Alternative proxies** - Explore additional BLS data (benefits coverage, training participation)

**Priority 4: Enhance Precision (Lower Importance)**
- ⚠️ **Longer time series** - Use multiple years of data for more stable estimates
- ⚠️ **Supplementary sources** - Compare BLS data to industry association surveys

---

### Conclusion: Can We Trust This Organizational Evidence?

**YES, with caveats:**

**Trustworthy for:**
- Establishing that turnover problem exists and is severe
- Documenting compensation levels and trends
- Showing productivity and tenure patterns
- Identifying associations between variables
- Providing industry benchmarks and context

**NOT sufficient alone for:**
- **Proving causation** (compensation → turnover reduction)
- **Predicting precise intervention effects** ("$5/hr raise = 20% less turnover")
- **Explaining mechanisms** (why/how relationships work)
- **Prescribing specific solutions** (what managers should do)

**The Solution:**
**Evidence-Based Management requires triangulating across ALL FOUR evidence types:**
1. **Organizational evidence** (BLS data) - Shows real-world patterns ✅
2. **Scientific evidence** (experiments) - Establishes causation ⚠️ NEEDED
3. **Practitioner evidence** (case studies) - Demonstrates feasibility ⚠️ NEEDED
4. **Stakeholder evidence** (surveys/interviews) - Provides context and buy-in ⚠️ NEEDED

Our organizational evidence is **high-quality and valuable**, but must be combined with other evidence types to support confident management decisions.

---

**Document Updated:** November 20, 2025  
**Assessment By:** Peter Siebentritt  
**Course:** MGT357 - Evidence-Based Management
